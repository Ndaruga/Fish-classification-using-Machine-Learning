{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c4514c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "# !pip install tensorflow \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee505d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Halichoeres scapularis', 'Lethrinius harak', 'Neopomacentrus demoiselle']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Fish categories available in the root dir\n",
    "\n",
    "root_dir = \"Fish images\"\n",
    "train_image_dir = os.path.join(root_dir, \"train\")\n",
    "val_image_dir = os.path.join(root_dir, \"val\")\n",
    "\n",
    "labels = []\n",
    "for label in os.listdir(train_image_dir):\n",
    "    labels.append(label)\n",
    "    \n",
    "display(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dc6039",
   "metadata": {},
   "source": [
    "### Loading the image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c59a7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "# !pip install opencv-python\n",
    "\n",
    "img_size = 200\n",
    "image_data = []\n",
    "\n",
    "def get_data(image_dir):\n",
    "    for label in labels:\n",
    "        image_path = os.path.join(image_dir, label)\n",
    "        class_num = labels.index(label)  # class num gives each fish category a label\n",
    "        for img in os.listdir(image_path):\n",
    "            img_arr = cv2.imread(os.path.join(image_path, img))\n",
    "    #             resize the images\n",
    "            resized_images = cv2.resize(img_arr, (img_size, img_size))\n",
    "            image_data.append([resized_images, class_num])\n",
    "\n",
    "    total_size = sys.getsizeof(image_data)\n",
    "\n",
    "    print(f\"Total memory used: {total_size}\")\n",
    "    return np.array(image_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c78d1629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory used: 41880\n",
      "Total memory used: 53080\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = get_data(train_image_dir)\n",
    "val = get_data(val_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8a0d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for feature, label in train:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "\n",
    "for feature, label in val:\n",
    "    x_val.append(feature)\n",
    "    y_val.append(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af22f2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32983259",
   "metadata": {},
   "source": [
    "#### Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c9c50ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = np.array(x_train) / 255\n",
    "x_val = np.array(x_val) / 255\n",
    "\n",
    "x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val.reshape(-1, img_size, img_size, 1)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d465a76",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd17484",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add first convo layer, maxpool and dropout\n",
    "model.add(Conv2D(filters = 16, kernel_size = (5,5), \n",
    "                 activation = 'relu', input_shape = (img_size, img_size,3)))\n",
    "model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Add a second convolution layer, maxpoling and dropout\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Add a third convolution layer, maxpoling and dropout\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# Add a flattening layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# add a layer with 1000 neurons\n",
    "model.add(Dense(1000, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# add a layer with 500 neurons\n",
    "model.add(Dense(500, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# add a layer with 250 neurons\n",
    "model.add(Dense(250, activation = 'relu'))\n",
    "\n",
    "# add a layer with 10 neurons\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df481c07",
   "metadata": {},
   "source": [
    "#### Model compile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac41d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(learning_rate=0.000001)\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "             optimizer = opt,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed7b615",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d684c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement callback function to stop training  when accuracy reaches 96%\n",
    "ACCURACY_THRESHOLD = 0.96\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "\tdef on_epoch_end(self, epoch, logs={}):\n",
    "\t\tif(logs.get('accuracy') > ACCURACY_THRESHOLD):\n",
    "\t\t\tprint(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))\n",
    "\t\t\tself.model.stop_training = True\n",
    "\n",
    "# Instantiate a callback object\n",
    "callbacks = myCallback()\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "                 shuffle = True,\n",
    "                 batch_size = 64,\n",
    "                 epochs = 300,\n",
    "                 validation_data = (x_val, y_val),\n",
    "                 callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b2ba9",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = model.evaluate(x_val, y_val)[1]*100\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db68ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Val'], loc ='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Val'], loc ='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27baade9",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5757731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "!pip install opencv-python\n",
    "\n",
    "import cv2\n",
    "# !pip install scikit-image\n",
    "from skimage.transform import resize\n",
    "\n",
    "foldername = \"./test_images/\" ###### folder for test images\n",
    "\n",
    "for img_count, filename in enumerate(os.listdir(foldername)):\n",
    "    img = plt.imread(os.path.join(foldername,filename))\n",
    "    resized_image = resize(img, (img_size, img_size, 3))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "      \n",
    "    predictions = model.predict(np.array([resized_image]))\n",
    "    print(predictions)\n",
    "    list_index = [0,1,2,3,4,5,6,7,8,9]\n",
    "    x = predictions\n",
    "\n",
    "  ################ display predictions as index from 0-9. ##############\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            if x[0][list_index[i]] > x[0][list_index[j]]:\n",
    "                #swap the numbers\n",
    "                temp = list_index[i]\n",
    "                list_index[i] = list_index[j]\n",
    "                list_index[j] = temp\n",
    "    display(list_index)\n",
    "    print(' '*50)\n",
    "    for i in range(len(labels)):\n",
    "        print(labels[list_index[i]], ':', round((predictions[0][list_index[i]] * 100),2), '%')\n",
    "    print(\"*\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71001206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
